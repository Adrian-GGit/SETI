{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from cv import Cadence\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.nn import ReLU, Conv2d, MaxPool2d, BatchNorm1d, BatchNorm2d\n",
    "from ignite.metrics import Recall, Precision, Accuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "conf_dict = {\n",
    "    \"batch_size\": 32,\n",
    "    \"learn_rate\": 1e-3,\n",
    "    \"min_learn_rate\": 1e-6,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"epochs\": 20,\n",
    "\n",
    "    \"transfer_model_name\": \"efficientnet_b0\", #\"tf_efficientnet_b5_ns\", #\n",
    "\n",
    "    \"train_dir\": \"../data/train/\",\n",
    "    \"train_csv\": \"train_labels.csv\",\n",
    "    \"test_dir\": \"../data/test/\",\n",
    "    \"test_csv\": \"sample_submission.csv\",\n",
    "    \"height\": 512,\n",
    "    \"width\": 512,\n",
    "\n",
    "    \"model\": \"schnaufnet_trained.pth\",\n",
    "\n",
    "    \"origin_height\": 273,\n",
    "    \"origin_width\": 256,\n",
    "\n",
    "    \"only_use\": 1000,\n",
    "    \"behaviours\": {\n",
    "        \"all\": \"use_all\",\n",
    "        \"only_1\": \"only_1\",\n",
    "        \"50_50\": \"50_50\",\n",
    "        \"weighted\": \"weighted\",\n",
    "    }\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SETIDataset(Dataset):\n",
    "\t\"\"\"Dataset for training data\"\"\"\n",
    "\tdef __init__(self, img_dir, test=False, transform=None, target_transform=None, use_cv_preprocessing=False):\n",
    "\t\tself.test = test\n",
    "\t\tif not self.test:\n",
    "\t\t\tself.img_labels = pd.read_csv(img_dir + conf_dict[\"train_csv\"])\n",
    "\t\telse:\n",
    "\t\t\tself.img_labels = pd.read_csv(img_dir + conf_dict[\"test_csv\"])\n",
    "\t\tself.img_labels['file_path'] = self.img_labels['id'].apply(self.get_file_path, dir=img_dir)\n",
    "\t\tself.img_dir = img_dir\n",
    "\t\tself.file_names = self.img_labels['file_path'].values\n",
    "\t\tself.transform = transform\n",
    "\t\tself.target_transform = target_transform\n",
    "\t\tself.use_cv_preprocessing = use_cv_preprocessing\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.img_labels)\n",
    "\n",
    "\t\t# testing with single batch - for example with 1k epochs\n",
    "\t\t# return conf_dict[\"batch_size\"]\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tfile_path = self.file_names[idx]\n",
    "\t\timage = np.load(file_path)\n",
    "\t\timage = image.astype(np.float32)\n",
    "\n",
    "\t\t# if self.use_cv_preprocessing:\n",
    "\t\t# \tcadence = Cadence(file_path)\n",
    "\t\t# \tcadence.cv()\n",
    "\n",
    "\t\timage = np.vstack(image).T\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image=image)['image']\n",
    "\t\telse:\n",
    "\t\t\timage = image[np.newaxis,:,:] # add dimension\n",
    "\t\t\timage = torch.from_numpy(image).float()\n",
    "\n",
    "\t\tlabel = torch.tensor(self.img_labels[\"target\"][idx]).float()\n",
    "\n",
    "\t\timage = image.repeat(3, 1, 1) # TODO: probably just repeating the single channel isnt the best way => probably converting grayscale to rgb is better\n",
    "\n",
    "\t\treturn image, label\n",
    "\n",
    "\tdef get_file_path(self, image_id, dir):\n",
    "\t\treturn dir + \"{}/{}.npy\".format(image_id[0], image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_conf_dict = {\n",
    "    \"conv_1_filter_output\": 8,\n",
    "    \"conv_2_filter_output\": 16,\n",
    "    \"conv_3_filter_output\": 16,\n",
    "}\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        print(\"initializing custom network\")\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(network_conf_dict[\"conv_3_filter_output\"] * 64 * 64, 32),\n",
    "            nn.ReLU(),\n",
    "            BatchNorm1d(32),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            BatchNorm1d(32),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        self.simple_cnn_stack = nn.Sequential(\n",
    "            Conv2d(3, network_conf_dict[\"conv_1_filter_output\"], kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(network_conf_dict[\"conv_1_filter_output\"]),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Conv2d(network_conf_dict[\"conv_1_filter_output\"], network_conf_dict[\"conv_2_filter_output\"], kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(network_conf_dict[\"conv_2_filter_output\"]),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Conv2d(network_conf_dict[\"conv_2_filter_output\"], network_conf_dict[\"conv_3_filter_output\"], kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(network_conf_dict[\"conv_3_filter_output\"]),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.simple_cnn_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "class NeuralNetworkWithBackbone(nn.Module):\n",
    "    def __init__(self, pretrained=False):\n",
    "        print(\"initializing transfer learning network\")\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(conf_dict[\"transfer_model_name\"], pretrained=pretrained, in_chans=1)\n",
    "        self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, 1)\n",
    "        # self.backbone = models.resnet50(pretrained=pretrained).to(device)\n",
    "        # for param in self.backbone.parameters():\n",
    "        #     param.requires_grad = False\n",
    "            \n",
    "        # self.backbone.fc = nn.Sequential(\n",
    "        #             nn.Linear(2048, 128),\n",
    "        #             nn.ReLU(inplace=True),\n",
    "        #             nn.Linear(128, 1)).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SETITrainValidation():\n",
    "    def __init__(self, train_dir, test_dir, load_model=False, val_split=0.25, use_backbone=True):\n",
    "        self.dataset_whole_train = SETIDataset(train_dir, transform=self.get_transforms(data=\"train\"))#, use_cv_preprocessing_preprocessing=True)\n",
    "        self.dataset_whole_val = SETIDataset(train_dir, transform=self.get_transforms(data=\"val\"))#, use_cv_preprocessing=True) # extra dataset fÃ¼r validation, da validation data nicht transformiert werden darf\n",
    "        # self.dataset_test = SETIDataset(test_dir, test=True, transform=self.get_transforms(data=\"test\"), use_cv_preprocessing=True)\n",
    "        if load_model:\n",
    "            self.model = self.load_model(use_backbone)\n",
    "        else:\n",
    "            self.model = self.new_model(use_backbone)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss() # nn.BCELoss() => needs sigmoid as activation function\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=conf_dict[\"learn_rate\"], weight_decay=conf_dict[\"weight_decay\"]) # torch.optim.SGD(self.model.parameters(), lr=conf_dict[\"learn_rate\"]) \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=conf_dict[\"epochs\"], eta_min=conf_dict[\"min_learn_rate\"], last_epoch=-1\n",
    "        )\n",
    "\n",
    "        self.val_split = val_split\n",
    "        self.train_dataloader = None\n",
    "        self.val_dataloader = None\n",
    "        self.train_losses = []\n",
    "        self.train_acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.accuracy = Accuracy()\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "\n",
    "    def get_transforms(self, data):\n",
    "        if data == 'train':\n",
    "            return A.Compose([\n",
    "                A.Resize(conf_dict[\"height\"], conf_dict[\"width\"]),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "        elif data == 'val' or data == 'test':\n",
    "            return A.Compose([\n",
    "                A.Resize(conf_dict[\"height\"], conf_dict[\"width\"]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "\n",
    "    def split(self, behaviour=\"all\", use_all=True):\n",
    "        dataset_whole_size = len(self.dataset_whole_train)\n",
    "        if use_all:\n",
    "            val_range = int(np.floor(self.val_split * dataset_whole_size))\n",
    "            train_range = dataset_whole_size - val_range\n",
    "            train_set, val_set = torch.utils.data.random_split(self.dataset_whole_train, [train_range, val_range])\n",
    "        else:\n",
    "            val_range = int(np.floor(self.val_split * conf_dict[\"only_use\"]))\n",
    "            train_range = conf_dict[\"only_use\"] - val_range\n",
    "            small_dataset_train = Subset(self.dataset_whole_train, np.random.randint(dataset_whole_size, size=conf_dict[\"only_use\"]))\n",
    "            train_set, val_set = torch.utils.data.random_split(small_dataset_train, [train_range, val_range])\n",
    "\n",
    "        if behaviour == conf_dict[\"behaviours\"][\"only_1\"]:\n",
    "            print(\"Using only 1 labeled data...\")\n",
    "            train_indices_1_labels = [train_set.indices[i] for i in range(len(train_set)) if self.dataset_whole_train.img_labels[\"target\"][train_set.indices[i]] == 1]\n",
    "            train_sampler = SubsetRandomSampler(train_indices_1_labels)\n",
    "            self.train_dataloader = DataLoader(self.dataset_whole_train, batch_size=conf_dict[\"batch_size\"], sampler=train_sampler)\n",
    "        if behaviour == conf_dict[\"behaviours\"][\"50_50\"]:\n",
    "            print(\"Using 50/50 data...\")\n",
    "            train_indices_1_labels = np.array([train_set.indices[i] for i in range(len(train_set)) if self.dataset_whole_train.img_labels[\"target\"][train_set.indices[i]] == 1])\n",
    "            train_indices_0_labels = np.array([train_set.indices[i] for i in range(len(train_set)) if self.dataset_whole_train.img_labels[\"target\"][train_set.indices[i]] == 0])\n",
    "            train_indices_0_labels_for_50_50 = list(np.random.choice(train_indices_0_labels, len(train_indices_1_labels), replace=False))\n",
    "            indices_50_50 = list(train_indices_1_labels) + train_indices_0_labels_for_50_50\n",
    "            train_sampler = SubsetRandomSampler(indices_50_50)\n",
    "            self.train_dataloader = DataLoader(self.dataset_whole_train, batch_size=conf_dict[\"batch_size\"], sampler=train_sampler)\n",
    "        elif behaviour == conf_dict[\"behaviours\"][\"weighted\"]:\n",
    "            print(\"Using weighted data...\")\n",
    "            train_labels = np.array([self.dataset_whole_train.img_labels[\"target\"][train_set.indices[i]] for i in range(len(train_set))])\n",
    "            class_sample_count = np.array(\n",
    "                [len(np.where(train_labels == t)[0]) for t in np.unique(train_labels)])\n",
    "            weight = 1. / class_sample_count\n",
    "            samples_weight = np.array([weight[t] for t in train_labels])\n",
    "            samples_weight = torch.from_numpy(samples_weight)\n",
    "            samples_weight = samples_weight.double()\n",
    "            sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "            self.train_dataloader = DataLoader(\n",
    "                train_set, batch_size=conf_dict[\"batch_size\"], sampler=sampler)\n",
    "        elif behaviour == conf_dict[\"behaviours\"][\"all\"]:\n",
    "            print(\"Using full data...\")\n",
    "            self.train_dataloader = DataLoader(train_set, batch_size=conf_dict[\"batch_size\"], shuffle=True)#, num_workers=2)\n",
    "        self.val_dataloader = DataLoader(val_set, batch_size=conf_dict[\"batch_size\"], shuffle=True)#, num_workers=2)\n",
    "\n",
    "        image, label = next(iter(self.train_dataloader))\n",
    "        print(\"Shape of image [N, C, H, W]: \", image.shape)\n",
    "        print(\"Shape of label: \", label.shape, label.dtype)\n",
    "\n",
    "        print(f\"Successfully splitted dataset!\\n Trainbatches: {len(self.train_dataloader)}\\n Validationbatches: {len(self.val_dataloader)}\")\n",
    "    \n",
    "    def train_loop(self):\n",
    "        print(\"Starting model training...\")\n",
    "        self.model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_loss_list = []\n",
    "        num_batches = len(self.train_dataloader)\n",
    "        print(\"Overall batches: \", num_batches)\n",
    "\n",
    "        for batch, (image, label) in tqdm(enumerate(self.train_dataloader), position=0, leave=True, desc='Evaluating'):\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            pred = self.model(image)\n",
    "            loss = self.loss_fn(pred.view(label.size(0)), label.to(torch.float32))\n",
    "            # print(\"real loss: \", loss.item())\n",
    "            epoch_loss_list.append(loss.item())\n",
    "            epoch_loss += loss.item() # add loss for whole batch\n",
    "\n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            predicted = torch.sigmoid(pred).round() # if precision gets higher => write own function which does not seperate <0.5 and >=0.5 like round currently does\n",
    "            self.accuracy.update((predicted, label))\n",
    "            self.precision.update((predicted, label))\n",
    "            self.recall.update((predicted, label))\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        self.train_losses.append(avg_epoch_loss)\n",
    "        self.train_acc.append(100*self.accuracy.compute())\n",
    "        print(f\"\"\"Test Error: \\n \n",
    "            Accuracy: {100*self.accuracy.compute():>2f}%, \\n\n",
    "            Recall: {100*self.recall.compute():>2f}%, \\n\n",
    "            Precision: {100*self.precision.compute():>2f}%, \\n\n",
    "            Avg loss: {avg_epoch_loss:>2f} \\n\n",
    "        \"\"\") # avg loss is summed losses for all batches divided with num batches\n",
    "        # print(f\"Epoch loss list: {epoch_loss_list}\")\n",
    "        plt.plot(epoch_loss_list, \"ro-\")\n",
    "        plt.title(\"Loss over epoch\")\n",
    "        plt.xlabel(\"Batch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "\n",
    "    def validation_loop(self):\n",
    "        print(\"Starting model validation...\")\n",
    "        epoch_loss = 0\n",
    "        num_batches = len(self.val_dataloader)\n",
    "        print(\"Overall batches: \", num_batches)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch, (image, label) in tqdm(enumerate(self.val_dataloader), position=0, leave=True, desc='Evaluating'):\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = self.model(image)\n",
    "                loss = self.loss_fn(pred.view(conf_dict[\"batch_size\"]), label.to(torch.float32))\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                predicted = torch.sigmoid(pred).round()\n",
    "\n",
    "                self.accuracy.update((predicted, label))\n",
    "                self.precision.update((predicted, label))\n",
    "                self.recall.update((predicted, label))\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / num_batches\n",
    "        self.val_losses.append(avg_epoch_loss)\n",
    "        self.val_acc.append(100*self.accuracy.compute())\n",
    "        print(f\"\"\"Test Error: \\n \n",
    "            Accuracy: {100*self.accuracy.compute():2f}%, \\n\n",
    "            Recall: {100*self.recall.compute():2f}%, \\n\n",
    "            Precision: {100*self.precision.compute():>2f}%, \\n\n",
    "            Avg loss: {avg_epoch_loss:>2f} \\n\n",
    "        \"\"\")\n",
    "\n",
    "    def load_model(self, use_backbone, pretrained=False):\n",
    "        print(\"Loading model...\")\n",
    "        self.model = self.new_model(use_backbone, pretrained)\n",
    "        self.model.load_state_dict(torch.load(conf_dict[\"model\"]))\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "\n",
    "    def save_model(self):\n",
    "        print(\"Training done! Saving model...\")\n",
    "        torch.save(self.model.state_dict(), conf_dict[\"model\"])\n",
    "        print(\"Saved model!\")\n",
    "\n",
    "    def new_model(self, use_backbone, pretrained=True):\n",
    "        print(\"Creating new Model...\")\n",
    "        if use_backbone:\n",
    "            # backbone = conf_dict[\"transfer_model_name\"]\n",
    "            backbone = \"resnset50\"\n",
    "            get_pretrained_model = \"pretrained\" if pretrained else \"not pretrained\"\n",
    "            print(f\"Using {backbone} Network {get_pretrained_model}...\")\n",
    "            return NeuralNetworkWithBackbone(pretrained).to(device)\n",
    "        else: \n",
    "            print(f\"Using custom Network...\")\n",
    "            return NeuralNetwork().to(device)\n",
    "\n",
    "    def plot_loss_acc_vs_epochs(self, train=True, plot_loss=True):\n",
    "        if train:\n",
    "            if plot_loss:\n",
    "                vs = \"Loss\"\n",
    "                plt.plot(self.train_losses, \"ro-\")\n",
    "            else:\n",
    "                vs = \"Accuracy\"\n",
    "                plt.plot(self.train_acc, \"ro-\")\n",
    "        else:\n",
    "            if plot_loss:\n",
    "                vs = \"Loss\"\n",
    "                plt.plot(self.val_losses, \"ro-\")\n",
    "            else:\n",
    "                vs = \"Accuracy\"\n",
    "                plt.plot(self.val_acc, \"ro-\")\n",
    "        plt.title(vs + \" vs Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(vs)\n",
    "        plt.show()\n",
    "\n",
    "    def train_model(self):\n",
    "        num_epochs = conf_dict[\"epochs\"]\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\\n-------------------------------\")\n",
    "            self.train_loop()\n",
    "        self.plot_loss_acc_vs_epochs(train=True, plot_loss=True)\n",
    "        self.plot_loss_acc_vs_epochs(train=True, plot_loss=False)\n",
    "        self.save_model()\n",
    "\n",
    "    def validate_model(self):\n",
    "        print(\"Validating model...\")\n",
    "        self.load_model(use_backbone=True)\n",
    "        # num_epochs = conf_dict[\"epochs\"]\n",
    "        # for epoch in range(num_epochs):\n",
    "        #     print(f\"Epoch {epoch+1}/{num_epochs}\\n-------------------------------\")\n",
    "        seti_trainer.validation_loop()\n",
    "        self.plot_loss_acc_vs_epochs(train=False, plot_loss=True)\n",
    "        self.plot_loss_acc_vs_epochs(train=False, plot_loss=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Model...\n",
      "Using custom Network...\n",
      "initializing custom network\n",
      "Using full data...\n",
      "Shape of image [N, C, H, W]:  torch.Size([32, 3, 512, 512])\n",
      "Shape of label:  torch.Size([32]) torch.float32\n",
      "Successfully splitted dataset!\n",
      " Trainbatches: 1407\n",
      " Validationbatches: 469\n",
      "Epoch 1/20\n",
      "-------------------------------\n",
      "Starting model training...\n",
      "Overall batches:  1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 1407it [37:58,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " \n",
      "            Accuracy: 88.724444%, \n",
      "\n",
      "            Recall: 1.502579%, \n",
      "\n",
      "            Precision: 8.945260%, \n",
      "\n",
      "            Avg loss: 0.387715 \n",
      "\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "-------------------------------\n",
      "Starting model training...\n",
      "Overall batches:  1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 85it [01:46,  1.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3aa659957179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseti_trainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSETITrainValidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train_dir\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test_dir\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_backbone\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mseti_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbehaviour\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"behaviours\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"all\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mseti_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# seti_trainer.validate_model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c2891af5ada0>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {epoch+1}/{num_epochs}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_loss_acc_vs_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_loss_acc_vs_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c2891af5ada0>\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# if precision gets higher => write own function which does not seperate <0.5 and >=0.5 like round currently does\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\SETI_CNN\\lib\\site-packages\\ignite\\metrics\\metric.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_reduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\SETI_CNN\\lib\\site-packages\\ignite\\metrics\\accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\SETI_CNN\\lib\\site-packages\\ignite\\metrics\\accuracy.py\u001b[0m in \u001b[0;36m_check_type\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mupdate_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_binary_multilabel_cases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mupdate_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\SETI_CNN\\lib\\site-packages\\ignite\\metrics\\accuracy.py\u001b[0m in \u001b[0;36m_check_binary_multilabel_cases\u001b[1;34m(self, output)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"For binary cases, y must be comprised of 0's and 1's.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seti_trainer = SETITrainValidation(conf_dict[\"train_dir\"], conf_dict[\"test_dir\"], load_model=False, use_backbone=False)\n",
    "seti_trainer.split(behaviour=conf_dict[\"behaviours\"][\"all\"], use_all=True)\n",
    "seti_trainer.train_model()\n",
    "# seti_trainer.validate_model()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd13562b0d53cf8f16620a562c29f3801c7294b99be841c5d9655a8ee4126191"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('seti': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
