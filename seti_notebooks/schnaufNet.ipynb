{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test = np.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\n",
    "plt.imshow(test, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from cv import Cadence\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.nn import ReLU, Conv2d, MaxPool2d, BatchNorm2d\n",
    "from ignite.metrics import Recall, Precision, Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "conf_dict = {\n",
    "    \"batch_size\": 32,\n",
    "    \"learn_rate\": 1e-3,\n",
    "    \"epochs\": 2,\n",
    "\n",
    "    \"train_dir\": \"../data/train/\",\n",
    "    \"train_csv\": \"train_labels.csv\",\n",
    "    \"test_dir\": \"../data/test/\",\n",
    "    \"test_csv\": \"sample_submission.csv\",\n",
    "    \"height\": 512,\n",
    "    \"width\": 512,\n",
    "\n",
    "    \"model\": \"schnaufnet_trained.pth\",\n",
    "\n",
    "    \"origin_height\": 273,\n",
    "    \"origin_width\": 256,\n",
    "\n",
    "    \"random_seed\": 10,\n",
    "\n",
    "    \"only_use\": 1000,\n",
    "}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SETIDataset(Dataset):\n",
    "\t\"\"\"Dataset for training data\"\"\"\n",
    "\tdef __init__(self, img_dir, test=False, transform=None, target_transform=None, use_cv=False):\n",
    "\t\tself.test = test\n",
    "\t\tif not self.test:\n",
    "\t\t\tself.img_labels = pd.read_csv(img_dir + conf_dict[\"train_csv\"])\n",
    "\t\telse:\n",
    "\t\t\tself.img_labels = pd.read_csv(img_dir + conf_dict[\"test_csv\"])\n",
    "\t\tself.img_labels['file_path'] = self.img_labels['id'].apply(self.get_file_path, dir=img_dir)\n",
    "\t\tself.img_dir = img_dir\n",
    "\t\tself.file_names = self.img_labels['file_path'].values\n",
    "\t\tself.transform = transform\n",
    "\t\tself.target_transform = target_transform\n",
    "\t\tself.use_cv = use_cv\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.img_labels)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tfile_path = self.file_names[idx]\n",
    "\t\timage = np.load(file_path)\n",
    "\t\timage = image.astype(np.float32)\n",
    "\n",
    "\t\tif self.use_cv:\n",
    "\t\t\tcadence = Cadence(file_path)\n",
    "\t\t\tcadence.cv()\n",
    "\n",
    "\t\timage = np.vstack(image).T\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timage = self.transform(image=image)['image']\n",
    "\t\telse:\n",
    "\t\t\timage = image[np.newaxis,:,:] # add dimension\n",
    "\t\t\timage = torch.from_numpy(image).float()\n",
    "\n",
    "\t\tlabel = torch.tensor(self.img_labels[\"target\"][idx])#.float()\n",
    "\t\treturn image, label\n",
    "\n",
    "\tdef get_file_path(self, image_id, dir):\n",
    "\t\treturn dir + \"{}/{}.npy\".format(image_id[0], image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = self.linear_relu()\n",
    "        self.simple_cnn_stack = self.cnn_layers()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.simple_cnn_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        y_pred = torch.sigmoid(x).squeeze()\n",
    "        return y_pred\n",
    "\n",
    "    def linear_relu(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(4 * 128 * 128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def cnn_layers(self):\n",
    "        return nn.Sequential(\n",
    "            Conv2d(1, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            BatchNorm2d(4),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SETITrainValidation():\n",
    "    def __init__(self, train_dir, test_dir, load_model=False, val_split=0.25):\n",
    "        self.dataset_whole_train = SETIDataset(train_dir, transform=self.get_transforms(data=\"train\"))#, use_cv=True)\n",
    "        self.dataset_whole_val = SETIDataset(train_dir, transform=self.get_transforms(data=\"val\"))#, use_cv=True) # extra dataset f√ºr validation, da validation data nicht transformiert werden darf\n",
    "        # self.dataset_test = SETIDataset(test_dir, test=True, transform=self.get_transforms(data=\"test\"), use_cv=True)\n",
    "        if load_model:\n",
    "            self.model = self.load_model()\n",
    "        else:\n",
    "            self.model = self.new_model()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=conf_dict[\"learn_rate\"])\n",
    "        self.val_split = val_split\n",
    "        self.train_dataloader = None\n",
    "        self.val_dataloader = None\n",
    "        self.train_losses = []\n",
    "        self.train_acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.accuracy = Accuracy()\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "\n",
    "    def get_transforms(self, data):\n",
    "        if data == 'train':\n",
    "            return A.Compose([\n",
    "                A.Resize(conf_dict[\"height\"], conf_dict[\"width\"]),\n",
    "                A.VerticalFlip(p = 0.5),\n",
    "                A.HorizontalFlip(p = 0.5),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        elif data == 'val' or data == 'test':\n",
    "            return A.Compose([\n",
    "                A.Resize(conf_dict[\"height\"], conf_dict[\"width\"]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "\n",
    "    def split(self, shuffle=True, use_all=True):\n",
    "        dataset_whole_size = len(self.dataset_whole_train)\n",
    "        if use_all:\n",
    "            indices = list(range(dataset_whole_size))\n",
    "            split = int(np.floor(self.val_split * dataset_whole_size))\n",
    "        else:\n",
    "            indices = list(range(conf_dict[\"only_use\"]))\n",
    "            split = int(np.floor(self.val_split * conf_dict[\"only_use\"]))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.seed(conf_dict[\"random_seed\"])\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        self.train_dataloader = DataLoader(self.dataset_whole_train, batch_size=conf_dict[\"batch_size\"], sampler=train_sampler)#, num_workers=2)\n",
    "        self.val_dataloader = DataLoader(self.dataset_whole_val, batch_size=conf_dict[\"batch_size\"], sampler=val_sampler)#, num_workers=2)\n",
    "\n",
    "        print(f\"Successfully splitted dataset!\\n Trainbatches: {len(self.train_dataloader)}\\n Validationbatches: {len(self.val_dataloader)}\")\n",
    "    \n",
    "    def train_loop(self):\n",
    "        print(\"Starting model training...\")\n",
    "        num_batches = len(self.train_dataloader)\n",
    "        test_loss = 0\n",
    "        for batch, (image, label) in enumerate(self.train_dataloader):\n",
    "            # print(f\"batch {batch}/{num_batches}\")\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            pred = self.model(image)\n",
    "            loss = self.loss_fn(pred, label.to(torch.float32))\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            predicted = pred.round().int()\n",
    "\n",
    "            self.accuracy.update((predicted, label))\n",
    "            self.precision.update((predicted, label))\n",
    "            self.recall.update((predicted, label))\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                loss = loss.item()\n",
    "                self.train_losses.append(loss)\n",
    "                self.train_acc.append(100*self.accuracy.compute())\n",
    "        print(f\"\"\"Test Error: \\n \n",
    "            Accuracy: {100*self.accuracy.compute()}%, \\n\n",
    "            Recall: {100*self.recall.compute()}%, \\n\n",
    "            Precision: {100*self.precision.compute()}%, \\n\n",
    "            Avg loss: {test_loss/num_batches:>8f} \\n\n",
    "        \"\"\")\n",
    "\n",
    "    def validation_loop(self):\n",
    "        print(\"Starting model validation...\")\n",
    "        num_batches = len(self.val_dataloader)\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch, (image, label) in enumerate(self.val_dataloader):\n",
    "                # print(f\"batch {batch}/{num_batches}\")\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                pred = self.model(image)\n",
    "                loss = self.loss_fn(pred, label.to(torch.float32)).item()\n",
    "                test_loss += loss\n",
    "\n",
    "                predicted = pred.round().int()\n",
    "\n",
    "                self.accuracy.update((predicted, label))\n",
    "                self.precision.update((predicted, label))\n",
    "                self.recall.update((predicted, label))\n",
    "\n",
    "                if batch % 100 == 0:\n",
    "                    self.val_losses.append(loss)\n",
    "                    self.val_acc.append(100*self.accuracy.compute())\n",
    "        print(f\"\"\"Test Error: \\n \n",
    "            Accuracy: {100*self.accuracy.compute()}%, \\n\n",
    "            Recall: {100*self.recall.compute()}%, \\n\n",
    "            Precision: {100*self.precision.compute()}%, \\n\n",
    "            Avg loss: {test_loss/num_batches:>8f} \\n\n",
    "        \"\"\")\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = self.new_model()\n",
    "        self.model.load_state_dict(torch.load(conf_dict[\"model\"]))\n",
    "        self.model.eval()\n",
    "\n",
    "    def save_model(self):\n",
    "        print(\"Training done! Saving model...\")\n",
    "        torch.save(self.model.state_dict(), conf_dict[\"model\"])\n",
    "        print(\"Saved model\")\n",
    "\n",
    "    def new_model(self):\n",
    "        return NeuralNetwork().to(device)\n",
    "\n",
    "    def plot_loss_acc_vs_epochs(self, train=True, plot_loss=True):\n",
    "        if train:\n",
    "            if plot_loss:\n",
    "                vs = \"Loss\"\n",
    "                plt.plot(self.train_losses, \"ro-\")\n",
    "            else:\n",
    "                vs = \"Accuracy\"\n",
    "                plt.plot(self.train_acc, \"ro-\")\n",
    "        else:\n",
    "            if plot_loss:\n",
    "                vs = \"Loss\"\n",
    "                plt.plot(self.val_losses, \"ro-\")\n",
    "            else:\n",
    "                vs = \"Accuracy\"\n",
    "                plt.plot(self.val_acc, \"ro-\")\n",
    "        plt.title(vs + \" vs Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(vs)\n",
    "        plt.show()\n",
    "\n",
    "    def train_model(self):\n",
    "        num_epochs = conf_dict[\"epochs\"]\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\\n-------------------------------\")\n",
    "            self.train_loop()\n",
    "        self.plot_loss_acc_vs_epochs(train=True, plot_loss=True)\n",
    "        self.plot_loss_acc_vs_epochs(train=True, plot_loss=False)\n",
    "        self.save_model()\n",
    "\n",
    "    def validate_model(self):\n",
    "        self.load_model()\n",
    "        num_epochs = conf_dict[\"epochs\"]\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\\n-------------------------------\")\n",
    "            seti_trainer.validation_loop()\n",
    "        self.plot_loss_acc_vs_epochs(train=False, plot_loss=True)\n",
    "        self.plot_loss_acc_vs_epochs(train=False, plot_loss=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully splitted dataset!\n",
      " Trainbatches: 24\n",
      " Validationbatches: 8\n",
      "Epoch 1/2\n",
      "-------------------------------\n",
      "Starting model training...\n",
      "loss:  0.6561903357505798\n",
      "Test Error: \n",
      " \n",
      "            Accuracy: 89.86666666666666%, \n",
      "\n",
      "            Recall: 0.0%, \n",
      "\n",
      "            Precision: 0.0%, \n",
      "\n",
      "            Avg loss: 0.481717 \n",
      "\n",
      "        \n",
      "Epoch 2/2\n",
      "-------------------------------\n",
      "Starting model training...\n",
      "loss:  0.4247397184371948\n",
      "Test Error: \n",
      " \n",
      "            Accuracy: 90.0%, \n",
      "\n",
      "            Recall: 0.0%, \n",
      "\n",
      "            Precision: 0.0%, \n",
      "\n",
      "            Avg loss: 0.356981 \n",
      "\n",
      "        \n",
      "self.train_losses:  [0.6561903357505798, 0.4247397184371948]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.train_losses:  [0.6561903357505798, 0.4247397184371948]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done! Saving model...\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "seti_trainer = SETITrainValidation(conf_dict[\"train_dir\"], conf_dict[\"test_dir\"], load_model=False)\n",
    "seti_trainer.split(use_all=False)\n",
    "seti_trainer.train_model()\n",
    "# seti_trainer.validate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd13562b0d53cf8f16620a562c29f3801c7294b99be841c5d9655a8ee4126191"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('seti': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
